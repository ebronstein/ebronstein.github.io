<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Eli Bronstein</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>
					<h1 id="logo"><a href="#">Eli Bronstein</a></h1>
					<p class="rev">moc.liamg@tsnorbile</p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#about_me" class="active">about me</a></li>
						<li><a href="#research">research</a></li>
						<li><a href="#projects">projects</a></li>
						<li><a href="#awards">awards</a></li>
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<li><a href="https://www.linkedin.com/in/eli-bronstein/" target="_blank" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://scholar.google.com/citations?user=uQRY6KoAAAAJ&hl=en" target="_blank" class="icon solid fa-user-graduate"><span class="label">Google Scholar</span></a></li>
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- About Me -->
							<section id="about_me">
								<!-- <div class="image main" data-position="center">
									<img src="images/banner.jpg" alt="" />
								</div> -->
								<div class="container">
									<header class="major">
										<h2>About Me</h2>
									</header>
									<p>I am a software engineer in <a href="https://waymo.com/" target="_blank">Waymo</a>â€™s <a href="https://waymo.com/research" target="_blank">research team</a>, working on learning-based planning agents for autonomous driving. I aim to make these agents generalizable, interactive, and robust to the diverse challenges of real-world driving. My research involves reinforcement learning, closed-loop training, representation learning, motion planning, and data-driven simulation.</p>
									<p>I received a B.S. in Electrical Engineering and Computer Science from UC Berkeley, where I worked with <a href="http://people.eecs.berkeley.edu/~anca/" target="_blank">Anca Dragan</a> on human-robot interaction and game-theoretic planning for autonomous vehicles. I also conducted research with <a href="http://people.eecs.berkeley.edu/~tomlin/" target="_blank">Claire Tomlin</a> on safe navigation in unknown environments.</p>
                                    <!-- <br><br> -->
									<a href="images/Resume_Eli_Bronstein.pdf" target="_blank" class="button primary icon small solid">CV</a>
								</div>
							</section>

						<!-- Research -->
							<section id="research">
								<div class="container">
									<h3>Research</h3>

									<!-- <ul class="feature-icons">
										<li class="icon solid fa-code">Write all the code</li>
										<li class="icon solid fa-cubes">Stack small boxes</li>
										<li class="icon solid fa-book">Read books and stuff</li>
										<li class="icon solid fa-coffee">Drink much coffee</li>
										<li class="icon solid fa-bolt">Lightning bolt</li>
										<li class="icon solid fa-users">Shadow clone technique</li>
									</ul> -->
									<div class="features">
										<article>
											<a class="image"><img src="images/hierarchical_driving_game.jpg" alt="" /></a>
											<div class="inner">
												<h4>Hierarchical Game-Theoretic Planning for Autonomous Vehicles</h4>
												<i>J.F. Fisac*, <b>E. Bronstein*</b>, E. Stefansson, D. Sadigh, S.S. Sastry, A.D. Dragan</i>
												<br>
												<p>International Conference on Robotics and Automation (ICRA), 2019
													<br>
													<a href="https://arxiv.org/pdf/1810.05766" target="_blank" class="button primary icon small solid">pdf</a>
													<a href="images/ICRA_2019_driving_game_poster.pdf" target="_blank" class="button primary icon small solid">poster</a>
												</p>
											</div>
											<p><br>The actions of an autonomous vehicle on the road affect and are affected by those of other drivers, whether overtaking, negotiating a merge, or avoiding an accident. This mutual dependence, best captured by dynamic game theory, creates a strong coupling between the vehicle's planning and its predictions of other drivers' behavior, and constitutes an open problem with direct implications on the safety and viability of autonomous driving technology. Unfortunately, dynamic games are too computationally demanding to meet the real-time constraints of autonomous driving in its continuous state and action space. In this paper, we introduce a novel game-theoretic trajectory planning algorithm for autonomous driving, that enables real-time performance by hierarchically decomposing the underlying dynamic game into a long-horizon" strategic" game with simplified dynamics and full information structure, and a short-horizon" tactical" game with full dynamics and a simplified information structure. The value of the strategic game is used to guide the tactical planning, implicitly extending the planning horizon, pushing the local trajectory optimization closer to global solutions, and, most importantly, quantitatively accounting for the autonomous vehicle and the human driver's ability and incentives to influence each other. In addition, our approach admits non-deterministic models of human decision-making, rather than relying on perfectly rational predictions. Our results showcase richer, safer, and more effective autonomous behavior in comparison to existing techniques.</p>
										</article>

										<article>
											<a class="image"><img src="images/safe_navigation.png" alt="" /></a>
											<div class="inner">
												<h4>An Efficient Reachability-Based Framework for Provably Safe Autonomous Navigation in Unknown Environments</h4>
												<i>A. Bajcsy*, S. Bansal*, <b>E. Bronstein</b>, V. Tolani, C.J. Tomlin</i>
												<br>
												<p>Conference on Decision and Control (CDC), 2019
													<br>
													<a href="https://arxiv.org/pdf/1905.00532" target="_blank" class="button primary icon small solid">pdf</a>
												</p>
											</div>
											<p><br>Real-world autonomous vehicles often operate in a priori unknown environments. Since most of these systems are safety-critical, it is important to ensure they operate safely in the face of environment uncertainty, such as unseen obstacles. Current safety analysis tools enable autonomous systems to reason about safety given full information about the state of the environment a priori. However, these tools do not scale well to scenarios where the environment is being sensed in real time, such as during navigation tasks. In this work, we propose a novel, real-time safety analysis method based on Hamilton-Jacobi reachability that provides strong safety guarantees despite environment uncertainty. Our safety method is planner-agnostic and provides guarantees for a variety of mapping sensors. We demonstrate our approach in simulation and in hardware to provide safety guarantees around a state-of-the-art vision-based, learning-based planner.</p>
										</article>

										<article>
											<a class="image"><img src="images/task_duration.png" alt="" /></a>
											<div class="inner">
												<h4>Generating Highly Predictive Probabilistic Models Of Task Durations</h4>
												<i>I.K. Isukapati, C. Igoe, <b>E. Bronstein</b>, V. Parimi, S.F. Smith</i>
												<br>
												<p>IEEE Transactions on Intelligent Transportation Systems, March 2020
													<br>
													<a href="https://www.ri.cmu.edu/wp-content/uploads/2020/03/Generating_Highly_Predictive_Probabilistic_Models_Of_Task_Durations__Final_Version.pdf" target="_blank" class="button primary icon small solid">pdf</a>
													<a href="https://riss.ri.cmu.edu/wp-content/uploads/2017/08/2017-RISS-Poster-BRONSTEIN-Eli-IGOE-Conor.compressed.pdf" target="_blank" class="button primary icon small solid">poster</a>
												</p>
											</div>
											<p><br>In many applications, uncertainty in the durations of tasks complicates the development of plans and schedules. This has given rise to a range of resilient planning and scheduling techniques that in some way rely on probabilistic models of task durations. In this paper we consider the problem of using historical data to develop probabilistic task models for such planning and scheduling techniques. We describe a novel, Bayesian hierarchical approach for constructing task duration distributions from past data, and demonstrate its effectiveness in constructing predictive probabilistic distribution models. Unlike traditional statistical learning techniques, the proposed approach relies on minimal data, is inherently adaptive to time varying task duration distribution, and provides a rich description of confidence for decision making. These ideas are demonstrated using historical data provided by a local transit authority on bus dwell times at urban bus stops. Our results show that the task distributions generated by our approach yield significantly more accurate predictions than those generated by standard regression techniques.</p>
										</article>
									</div>
								</div>
							</section>

						<!-- Projects -->
							<section id="projects">
								<div class="container">
									<h3>Projects</h3>
									<div class="features">
										<article>
											<a class="image"><img src="images/grasp_transfer_by_parts_lightbulb.png" alt="" /></a>
											<div class="inner">
												<h4>Grasp Transfer by Parts</h4>
												<p>Class project for  EECS 106B: Robotic Manipulation and Interaction
													<br>
													<a href="https://sites.google.com/berkeley.edu/grasptransferbyparts/home" target="_blank" class="button primary icon small solid">website</a>
												</p>
											</div>
											<p><br>Grasping, which focuses on enabling robots to manipulate objects, is challenging because of the large space of possible grasps and object poses that must be considered. We seek to decrease the complexity of planning grasps on objects by 1) segmenting a query object into parts, and 2) transferring precomputed good grasps to these parts from parts of previously seen objects, with the novel consideration that the query object and other object need not be from the same semantic class.</p>
										</article>

										<article>
											<a class="image"><img style="width:50%" src="images/pong.jpg" alt="" /></a>
											<div class="inner">
												<h4>Extending Single-Task Policy Distillation in Reinforcement Learning</h4>
												<p>Class project for CS 294-112: Deep Reinforcement Learning
													<br>
													<a href="images/Extending_Single-Task_Policy_Distillation_in_Reinforcement_Learning.pdf" target="_blank" class="button primary icon small solid">pdf</a>
												</p>
											</div>
											<p><br>Deep learning models with a large number of parameters are often unnecessarily large and time-consuming during both training and prediction. Policy distillation seeks to address this concern by distilling the policy from a larger teacher network to a smaller student network. We aim to improve the student networkâ€™s training sample complexity by considering 1) how a student networkâ€™s exploration strategy affects its learning behavior, and 2) how a student network can efficiently learn from multiple teachers of varying expertise.

											To address the first question, we conduct experiments with teacher and student Deep Q-Networks in the Pong environment and test several student exploration strategies (greedy, epsilon-greedy, Boltzmann, and Bayesian exploration with dropout), finding that greedy and Bayesian strategies result in minimal sample complexity.

											To explore the second question, we pose the problem of multi-teacher single-task policy distillation as a multi-armed bandit problem, where the teachers are the arms and the payoffs are the rewards the student receives after learning from the teachers. We show that non-contextual bandit algorithms such as random, epsilon-greedy, and UCB1 perform well when learning from multiple teachers, and UCB1 learns efficiently even when the teachers are of varying expertise. We also suggest how contextual bandit algorithms can use the state observation to decide which teacher to learn from, thus learning a holistic policy over the entire state space from teachers that are experts in subparts of the state space.</p>
										</article>
									</div>
								</div>
							</section>

						<!-- Awards -->
							<section id="awards">
								<div class="container">
									<h3>Awards</h3>
									<ul>
										<li>National Science Foundation <a href="https://www.nsf.gov/cise/CSGrad4US/" target="_blank">CSGrad4US Graduate Fellowship</a> (2022)</li>
									    <li>National Science Foundation Research Experience for Undergraduates (REU) Scholarship Recipient (2017)</li>
									</ul>
								</div>
							</section>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Eli Bronstein, 2022.</li><li>Made with <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			<!-- </div> -->

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
